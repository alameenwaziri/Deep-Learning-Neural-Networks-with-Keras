{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alameenwaziri/Deep-Learning-Neural-Networks-with-Keras/blob/main/Building_Advanced_Transformers_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdb08ae3-6e40-4e75-900d-da6aeb43993a"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37fcf9da-864f-4d9e-b0da-5f995396dd17"
      },
      "source": [
        "# Building Advanced Transformers\n",
        "\n",
        "Implement and experiment with advanced Transformer models using Keras.\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "\n",
        "- Implement advanced Transformer models using Keras.\n",
        "\n",
        "- Apply Transformers to real-world sequential data tasks.\n",
        "\n",
        "- Build, train, and evaluate Transformer models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1f99b57-2c59-4862-8fac-9ff12df49057"
      },
      "source": [
        "## Step-by-Step Instructions:\n",
        "\n",
        "### Step 1: Import necessary libraries\n",
        "\n",
        "Import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f75f47fd-ad84-4ee2-bc2c-6311baafb7fb",
        "outputId": "aadedab7-909c-4620-be41-1a76d1eff858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow pyarrow\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7b493f8-9f56-4ea0-97cf-bb6c4f3ebfab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84a6fc6c-1977-442d-a622-0794062257e1"
      },
      "source": [
        "####  Setup the Environment to generate synthetic stock price data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a1644f-1983-4208-823e-1923cc2be243",
        "outputId": "1b2e89d9-929f-47c6-fc94-617f0fbd7bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthetic stock_prices.csv created and loaded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic stock price dataset\n",
        "np.random.seed(42)\n",
        "data_length = 2000  # Adjust data length as needed\n",
        "trend = np.linspace(100, 200, data_length)\n",
        "noise = np.random.normal(0, 2, data_length)\n",
        "synthetic_data = trend + noise\n",
        "\n",
        "# Create a DataFrame and save as 'stock_prices.csv'\n",
        "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
        "data.to_csv('stock_prices.csv', index=False)\n",
        "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b9f0a73-eb0e-4c0b-adb1-2f068a5f33d7",
        "outputId": "145d34d8-82d2-43d4-94e7-09e4de225b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (1899, 100, 1)\n",
            "Shape of Y: (1899,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stock_prices.csv')\n",
        "data = data[['Close']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, Y = create_dataset(data, time_step)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b218abb-d401-4727-a317-2e381c2d1103"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "`tensorflow` is the main library for machine learning in Python.  \n",
        "\n",
        "`stock_prices.csv` is the data set that is loaded.\n",
        "\n",
        "`MinMaxScaler` method is used to normalize the data.  \n",
        "\n",
        "`create_dataset`method is used to prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "834533dc-d545-4225-abe5-bf6702a63b29"
      },
      "source": [
        "### Step 2: Implement Multi-Head Self-Attention\n",
        "\n",
        "Define the Multi-Head Self-Attention mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c17e005d-bb96-4e35-84f6-1b64ff95198f"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9559b2f1-6474-4761-b3e1-e8d463be0b80"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously.\n",
        "\n",
        "- The attention parameter computes the attention scores and weighted sum of the values.\n",
        "\n",
        "- The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
        "\n",
        "- The call method applies the self-attention mechanism and combines the heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19eacfd8-cf47-49e2-b3d6-37f4a9f7fc91"
      },
      "source": [
        "### Step 3: Implement Transformer block\n",
        "\n",
        "Define the Transformer block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d98b16c-1273-47db-a7c1-1b86c156f923"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ac1a9c-a6fd-426a-8150-7d73bbda0260"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
        "\n",
        "- Dropout is used to prevent overfitting.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44236ed7-6e90-4272-8ddb-0b23f162e801"
      },
      "source": [
        "### Step 4: Implement Encoder Layer\n",
        "\n",
        "Define the Encoder layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ae62188-09fc-4efa-be57-4ccdc7388d06"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9c4a011-d544-467e-8dd4-5b785a226924"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
        "\n",
        "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
        "\n",
        "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4d804e1-689b-4876-be82-6a65a1381154"
      },
      "source": [
        "### Step 5: Implement Transformer encoder\n",
        "\n",
        "Define the Transformer Encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cc36bd-6bd8-4334-8571-d3ec5a17c69e",
        "outputId": "9ef2a664-2680-4048-c6f1-849e86b46cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "inputs = tf.random.uniform((1, 100, embed_dim))\n",
        "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training'\n",
        "print(outputs.shape)  # Should print (1, 100, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58914cf7-70fa-4e3a-9a13-2c7ea907f91e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade3a268-1398-489b-965b-63d7cb4f70b9"
      },
      "source": [
        "### Step 6: Build and Compile the Transformer model\n",
        "\n",
        "Integrate the Transformer Encoder into a complete model for sequential data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "973dc690-4c2f-4edf-aa69-63be850f3ece",
        "outputId": "74031258-aefa-470d-b2b7-28e8ed952588"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m793,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │          \u001b[38;5;34m12,801\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the necessary parameters\n",
        "\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "# Define the Transformer Encoder\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X.shape[1], X.shape[2])\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Project the inputs to the embed_dim\n",
        "x = tf.keras.layers.Dense(embed_dim)(inputs)\n",
        "encoder_outputs = transformer_encoder(x)\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "outputs = tf.keras.layers.Dense(1)(flatten)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51fb9cf5-9372-4794-add8-5f2392838a23"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
        "\n",
        "- The model is then compiled with the Adam optimizer and mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5978fb3-3a42-44f9-b146-68cad41ba794"
      },
      "source": [
        "### Step 7: Train the Transformer model\n",
        "\n",
        "Train the model on the prepared dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65d7244-5b68-4ba7-9f94-27cb0022e768",
        "outputId": "eabedb1a-484d-42d7-dd6f-dbebf0c80f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 735ms/step - loss: 13.2041\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 704ms/step - loss: 0.2086\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 713ms/step - loss: 0.1706\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 702ms/step - loss: 0.1566\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 711ms/step - loss: 0.2102\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 795ms/step - loss: 0.1649\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 714ms/step - loss: 0.1665\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 694ms/step - loss: 0.1103\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 694ms/step - loss: 0.2204\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 693ms/step - loss: 0.1440\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 722ms/step - loss: 0.1200\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 712ms/step - loss: 0.0933\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 705ms/step - loss: 0.1302\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 703ms/step - loss: 0.0996\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 695ms/step - loss: 0.0803\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 696ms/step - loss: 0.0564\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 707ms/step - loss: 0.0557\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 707ms/step - loss: 0.0473\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 697ms/step - loss: 0.0395\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 702ms/step - loss: 0.0313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e9f3bca410>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aa04758-fc9b-4fb2-b00e-535326f274a6"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98c73638-a697-414f-91b4-3cf1455015db"
      },
      "source": [
        "### Step 8: Evaluate and Make Predictions\n",
        "\n",
        "Evaluate the model's performance and make predictions on the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "14dc0b3a-758e-407e-b392-cd3b9a1c2fa1",
        "outputId": "f40bdd74-14f2-403d-f841-b78b0c531291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "\n",
        "# Plot the predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(data, label='True Data')\n",
        "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7654ac42-8a22-4304-b257-2d344dcd360f"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
        "\n",
        "- The true data and predictions are plotted to visualize the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9e038e-2bd0-48df-a073-317143f34a65"
      },
      "source": [
        "## Practice Exercises:\n",
        "\n",
        " ### Exercise 1: Add dropout to the Transformer model\n",
        "\n",
        " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Add a dropout layer after the Flatten layer in the model.\n",
        "\n",
        "- Set the dropout rate to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658814d0-81f8-4e42-9196-f58a8ba73174",
        "outputId": "e1bf98c5-1daa-495d-9e41-fd9fe194fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 727ms/step - loss: 5.6166\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 754ms/step - loss: 1.1084\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 717ms/step - loss: 0.6121\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 739ms/step - loss: 0.2556\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 737ms/step - loss: 0.0994\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 730ms/step - loss: 0.0679\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 730ms/step - loss: 0.0586\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 741ms/step - loss: 0.0495\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 735ms/step - loss: 0.0309\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 730ms/step - loss: 0.0243\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 729ms/step - loss: 0.0229\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 743ms/step - loss: 0.0231\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 736ms/step - loss: 0.0197\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 736ms/step - loss: 0.0202\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 726ms/step - loss: 0.0186\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 729ms/step - loss: 0.0179\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 738ms/step - loss: 0.0152\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 730ms/step - loss: 0.0167\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 750ms/step - loss: 0.0194\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 0.0168\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 229ms/step - loss: 0.0017\n",
            "Test loss: 0.0023836076725274324\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "\n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac4285e-8886-47e6-8946-e10493394914"
      },
      "source": [
        "### Exercise 2: Experiment with different batch sizes\n",
        "\n",
        "**Objective: Observe the impact of different batch sizes on model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Train the model with a batch size of 16.\n",
        "\n",
        "- Train the model with a batch size of 64.\n",
        "\n",
        "- Compare the training time and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960017cb-8c0e-4d60-9447-81f4be936add",
        "outputId": "56e5cb10-9638-43c3-f3ad-7683266ee0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 401ms/step - loss: 0.0151\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 365ms/step - loss: 0.0345\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 365ms/step - loss: 0.0370\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 375ms/step - loss: 0.0275\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 364ms/step - loss: 0.0155\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 365ms/step - loss: 0.0244\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 374ms/step - loss: 0.0165\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 364ms/step - loss: 0.0277\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 369ms/step - loss: 0.0182\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 364ms/step - loss: 0.0181\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 376ms/step - loss: 0.0254\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 365ms/step - loss: 0.0429\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 377ms/step - loss: 0.0180\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 365ms/step - loss: 0.0183\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 364ms/step - loss: 0.0189\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 376ms/step - loss: 0.0568\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 364ms/step - loss: 0.0183\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 373ms/step - loss: 0.0093\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 368ms/step - loss: 0.0093\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 366ms/step - loss: 0.0204\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 237ms/step - loss: 0.0056\n",
            "Test loss with batch size 16: 0.009686553850769997\n",
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - loss: 0.0117\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 0.0045\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 0.0033\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 0.0031\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0029\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: 0.0030\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 0.0037\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 0.0027\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - loss: 0.0028\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0028\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: 0.0025\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - loss: 0.0024\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0031\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - loss: 0.0028\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 0.0031\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0033\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - loss: 0.0035\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - loss: 0.0028\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: 0.0026\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - loss: 0.0025\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 230ms/step - loss: 0.0010\n",
            "Test loss with batch size 64: 0.0015166738303378224\n"
          ]
        }
      ],
      "source": [
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "359aec66-7a1c-4f1b-9be3-6a7f90905c3d"
      },
      "source": [
        "### Exercise 3: Use a different activation function\n",
        "\n",
        " **Objective: Understand how different activation functions impact the model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Change the activation function of the Dense layer to `tanh`.\n",
        "\n",
        "- Train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "194078fc-6b2a-4543-8200-b3d6c9e71e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca338d2b-74fa-47b2-c7a9-72a546ec9611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 716ms/step - loss: 0.2332\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 706ms/step - loss: 0.0255\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 730ms/step - loss: 0.0094\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 711ms/step - loss: 0.0074\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 706ms/step - loss: 0.0031\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 729ms/step - loss: 0.0028\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 706ms/step - loss: 0.0028\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 708ms/step - loss: 0.0019\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 723ms/step - loss: 0.0088\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 709ms/step - loss: 0.0017\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 708ms/step - loss: 0.0035\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 736ms/step - loss: 0.0025\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 707ms/step - loss: 0.0014\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 715ms/step - loss: 0.0026\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 740ms/step - loss: 0.0013\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 714ms/step - loss: 0.0015\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 709ms/step - loss: 0.0031\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 708ms/step - loss: 0.0014\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 706ms/step - loss: 0.0020\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 732ms/step - loss: 0.0019\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 231ms/step - loss: 0.0053\n",
            "Test loss with tanh activation: 0.0031929872930049896\n"
          ]
        }
      ],
      "source": [
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27b057d6-dab5-465e-bfc2-a2e1238297ad"
      },
      "source": [
        "## Conclusion\n",
        "Built an advanced Transformer model using Keras and applied it to a time series forecasting task. Defined and implemented multi-head self-attention, Transformer blocks, encoder layers, and integrated them into a complete Transformer model. By experimenting with different configurations and training the model, further improvements could be made to its performance and apply it to various sequential data tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d130ec79-66d4-4f13-9e97-f5d0508ec412"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}